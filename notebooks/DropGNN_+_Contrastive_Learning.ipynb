{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv46oqe2DpeK"
   },
   "source": [
    "# DropGNN + Contrastive Learning Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdzu3FAaGB64"
   },
   "source": [
    "Work based off of DropGNN\n",
    "\n",
    "https://arxiv.org/pdf/2111.06283.pdf \n",
    "\n",
    "https://github.com/KarolisMart/DropGNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cmcqq2oyHCvQ"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Torch Geometric \n",
    "try: \n",
    "    from torch_geometric.data import DataLoader, Data\n",
    "    from torch_geometric.data.dataloader import Collater\n",
    "    from torch_geometric.datasets import TUDataset\n",
    "    from torch_geometric.utils import degree\n",
    "    from torch_geometric.utils.convert import from_networkx\n",
    "    from torch_geometric.nn import GINConv, GINEConv, global_add_pool\n",
    "except ModuleNotFoundError: \n",
    "    !pip install torch_geometric\n",
    "    from torch_geometric.data import DataLoader, Data\n",
    "    from torch_geometric.data.dataloader import Collater\n",
    "    from torch_geometric.datasets import TUDataset\n",
    "    from torch_geometric.utils import degree\n",
    "    from torch_geometric.utils.convert import from_networkx\n",
    "    from torch_geometric.nn import GINConv, GINEConv, global_add_pool\n",
    "    \n",
    "# Pytorch Metric Learning\n",
    "try: \n",
    "    from pytorch_metric_learning import losses\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pytorch-metric-learning\n",
    "    from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4VpVUxbJeBQ"
   },
   "source": [
    "## Import Dataset\n",
    "\n",
    "Use the IMDB-Binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kpop90ZxIaZW"
   },
   "outputs": [],
   "source": [
    "class MyFilter(object):\n",
    "    def __call__(self, data):\n",
    "        return data.num_nodes <= 70\n",
    "\n",
    "class MyPreTransform(object):\n",
    "    def __call__(self, data):\n",
    "        data.x = degree(data.edge_index[0], data.num_nodes, dtype=torch.long)\n",
    "        data.x = F.one_hot(data.x, num_classes=69).to(torch.float)\n",
    "        return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oPb5CIfZJ0TV"
   },
   "outputs": [],
   "source": [
    "# Download data \n",
    "path = osp.join(osp.dirname(osp.realpath(\"./\")), 'data', f'IMDB-BINARY')\n",
    "\n",
    "dataset = TUDataset(\n",
    "    path, \n",
    "    name = \"IMDB-BINARY\", \n",
    "    pre_transform = MyPreTransform(), \n",
    "    pre_filter = MyFilter()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1u0WXdtb_Zj",
    "outputId": "db3223f4-c7a7-4096-aa77-046cfad4b008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB-BINARY(996)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtqTi8B8HrCb"
   },
   "source": [
    "## Original DropGIN Model\n",
    "\n",
    "DropGIN model found in DropGNN paper modified to work without CLI arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "C1N3ZszgDkOF"
   },
   "outputs": [],
   "source": [
    "class DropGIN(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout, use_aux_loss=True, num_runs=20, p=0.1):\n",
    "        super(DropGIN, self).__init__()\n",
    "\n",
    "        # Set starting parameters for model \n",
    "        num_features = dataset.num_features # Number of initial features \n",
    "        dim = hidden_units # Number of hidden units per layer \n",
    "        self.dropout = dropout # Dropout rate \n",
    "        self.use_aux_loss = use_aux_loss\n",
    "        self.num_runs = num_runs\n",
    "        self.p = p\n",
    "\n",
    "        # Number of layers in model\n",
    "        self.num_layers = 4\n",
    "\n",
    "        self.convs = nn.ModuleList() # Made of num_layers GINConv (linear -> batchnorm1d -> relu -> linear)\n",
    "        self.bns = nn.ModuleList() # Made of num_layers BatchNorm1d \n",
    "        self.fcs = nn.ModuleList() # Made of num_layers + 1 Linear layers mapping from num_features or dim to num_classes\n",
    "\n",
    "        # Add initial layer from num_features to dim \n",
    "        self.convs.append(GINConv(nn.Sequential(nn.Linear(num_features, dim), nn.BatchNorm1d(dim), nn.ReLU(), nn.Linear(dim, dim))))\n",
    "        self.bns.append(nn.BatchNorm1d(dim))\n",
    "        self.fcs.append(nn.Linear(num_features, dataset.num_classes))\n",
    "        self.fcs.append(nn.Linear(dim, dataset.num_classes))\n",
    "\n",
    "        # Add additional layers from dim to dim \n",
    "        for i in range(self.num_layers-1):\n",
    "            self.convs.append(GINConv(nn.Sequential(nn.Linear(dim, dim), nn.BatchNorm1d(dim), nn.ReLU(), nn.Linear(dim, dim))))\n",
    "            self.bns.append(nn.BatchNorm1d(dim))\n",
    "            self.fcs.append(nn.Linear(dim, dataset.num_classes))\n",
    "\n",
    "        # Use aux_loss for dropGNN: made of num_layers + 1 linear layers \n",
    "        # Adds new module list of linear layers \n",
    "        if self.use_aux_loss:\n",
    "            self.aux_fcs = nn.ModuleList()\n",
    "            self.aux_fcs.append(nn.Linear(num_features, dataset.num_classes))\n",
    "            for i in range(self.num_layers):\n",
    "                self.aux_fcs.append(nn.Linear(dim, dataset.num_classes))\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Resets parameters for Linear, GINConv, and BatchNorm1d layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, GINConv):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.reset_parameters()\n",
    "\n",
    "    def forward(self, data, temp):\n",
    "        # Note: num_runs in DropGNN is average number of nodes in each graph in dataset\n",
    "        # Note: p is 2 * 1 / (1 + gamma), but for this project, p is selected to create augmented views \n",
    "\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "            \n",
    "        # Do runs in parallel, by repeating the graphs in the batch\n",
    "        x = x.unsqueeze(0).expand(self.num_runs, -1, -1).clone()   # Flattens features and creates num_runs copy of them \n",
    "        drop = torch.bernoulli(torch.ones([x.size(0), x.size(1)], device=x.device) * self.p).bool()   #  Returns a tensor of randomly dropped nodes based on p (p = probability of dropping) \n",
    "        x[drop] = torch.zeros([drop.sum().long().item(), x.size(-1)], device=x.device)  # Drop nodes from data  \n",
    "        del drop\n",
    "\n",
    "        # Run augmented subgraph through model \n",
    "        outs = [x]  # Used to store view of x after each layer \n",
    "        x = x.view(-1, x.size(-1))  # Swap dimensions of data features \n",
    "        run_edge_index = edge_index.repeat(1, self.num_runs) + torch.arange(self.num_runs, device=edge_index.device).repeat_interleave(edge_index.size(1)) * (edge_index.max() + 1) # Expand edge_index and augment values\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, run_edge_index)  # Run node features and edge indices through CONV layer \n",
    "            x = self.bns[i](x)  # Run resulting values through BatchNorm1d\n",
    "            x = F.relu(x)   # Run final values through RELU\n",
    "            outs.append(x.view(self.num_runs, -1, x.size(-1)))    # Rearrange dimensions and append to outs \n",
    "        del run_edge_index\n",
    "\n",
    "        # TODO: Replace this with replacable head for contrastive learning and making predictions \n",
    "        # Aggregates results of runs by summing mean and applying random dropout (not dropping out nodes)\n",
    "        out = None\n",
    "        for i, x in enumerate(outs):\n",
    "            x = x.mean(dim=0)\n",
    "            x = global_add_pool(x, batch)\n",
    "            x = F.dropout(self.fcs[i](x), p=self.dropout, training=self.training)\n",
    "            if out is None:\n",
    "                out = x\n",
    "            else:\n",
    "                out += x\n",
    "\n",
    "        if self.use_aux_loss:\n",
    "            aux_out = torch.zeros(self.num_runs, out.size(0), out.size(1), device=out.device)\n",
    "            run_batch = batch.repeat(self.num_runs) + torch.arange(self.num_runs, device=edge_index.device).repeat_interleave(batch.size(0)) * (batch.max() + 1)\n",
    "            for i, x in enumerate(outs):\n",
    "                x = x.view(-1, x.size(-1))\n",
    "                x = global_add_pool(x, run_batch)\n",
    "                x = x.view(self.num_runs, -1, x.size(-1))\n",
    "                x = F.dropout(self.aux_fcs[i](x), p=self.dropout, training=self.training)\n",
    "                aux_out += x\n",
    "\n",
    "            # Returns probabilities of each class based on aggregated results \n",
    "            return F.log_softmax(out, dim=-1), F.log_softmax(aux_out, dim=-1)\n",
    "        else:\n",
    "            return F.log_softmax(out, dim=-1), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropGNN + Contrastive Learning Model\n",
    "\n",
    "Copy of DropGIN model with Contrastive Learning Forward methods added\n",
    "\n",
    "Changes made: \n",
    "- Added more arguments when initializing model instead of depending on global variables \n",
    "- Changed how the forward function is called and run\n",
    "- Add two different forward functions\n",
    "    - Contrastive Forward: Runs graph data through the base model and returns a representation vector \n",
    "    - Prediction Forward: Runs graph data through the base model and returns a probablity vector for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropGNN_Contrastive(nn.Module):\n",
    "    def __init__(self, num_features, num_reps, num_classes, hidden_units, use_aux_loss=True):\n",
    "        super(DropGNN_Contrastive, self).__init__()\n",
    "\n",
    "        # Set starting parameters for model \n",
    "        self.num_features = num_features   # Number of initial features \n",
    "        self.num_reps = num_reps           # Number of features in representation vector \n",
    "        self.num_classes = num_classes     # Number of different classes\n",
    "        self.dim = hidden_units            # Number of units for hidden layers\n",
    "        self.use_aux_loss = use_aux_loss   # Whether to include aux loss to total loss\n",
    "\n",
    "        # Number of layers in model\n",
    "        self.num_layers = 4\n",
    "\n",
    "        self.convs = nn.ModuleList()                     # Made of num_layers GINConv (linear -> batchnorm1d -> relu -> linear)\n",
    "        self.bns = nn.ModuleList()                       # Made of num_layers BatchNorm1d \n",
    "        self.reps = nn.Linear(self.dim, self.num_reps)   # Layer between base model and contrastive learning representation\n",
    "        self.fcs = nn.ModuleList()                       # Made of num_layers + 1 Linear layers mapping from num_features or dim to num_reps\n",
    "\n",
    "        # Add initial layer from num_features to dim \n",
    "        self.convs.append(GINConv(nn.Sequential(nn.Linear(self.num_features, self.dim), nn.BatchNorm1d(self.dim), nn.ReLU(), nn.Linear(self.dim, self.dim))))\n",
    "        self.bns.append(nn.BatchNorm1d(self.dim))\n",
    "        self.fcs.append(nn.Linear(self.num_features, self.num_classes))\n",
    "        self.fcs.append(nn.Linear(self.dim, self.num_classes))\n",
    "\n",
    "        # Add additional layers from dim to dim \n",
    "        for i in range(self.num_layers-1):\n",
    "            self.convs.append(GINConv(nn.Sequential(nn.Linear(self.dim, self.dim), nn.BatchNorm1d(self.dim), nn.ReLU(), nn.Linear(self.dim, self.dim))))\n",
    "            self.bns.append(nn.BatchNorm1d(self.dim))\n",
    "            self.fcs.append(nn.Linear(self.dim, self.num_classes))\n",
    "\n",
    "        # Use aux_loss for dropGNN: made of num_layers + 1 linear layers \n",
    "        # Adds new module list of linear layers \n",
    "        if self.use_aux_loss:\n",
    "            self.aux_fcs = nn.ModuleList()\n",
    "            self.aux_fcs.append(nn.Linear(self.num_features, self.num_classes))\n",
    "            for i in range(self.num_layers):\n",
    "                self.aux_fcs.append(nn.Linear(self.dim, self.num_classes))\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        # Resets parameters for Linear, GINConv, and BatchNorm1d layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, GINConv):\n",
    "                m.reset_parameters()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.reset_parameters()\n",
    "                \n",
    "    def forward(self, data, mode=\"test\", p=None, dropout=None, num_runs=20):\n",
    "        # Runs different modes based on whether running contrastive loss or making predictions\n",
    "        if mode == 'contrastive':\n",
    "            return self.contrastive(data, p, num_runs)\n",
    "        else:\n",
    "            return self.prediction(data, dropout, num_runs)\n",
    "        \n",
    "    def contrastive(self, data, p, num_runs):\n",
    "        # Trains contrastive model and representation vector model \n",
    "        \n",
    "        # Note: num_runs in DropGNN is average number of nodes in each graph in dataset\n",
    "        # Note: p is 2 * 1 / (1 + gamma), but for this project, p is selected to create augmented views \n",
    "        \n",
    "        self.p = p\n",
    "        self.num_runs = num_runs\n",
    "        \n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch \n",
    "        \n",
    "        # Do runs in parallel, by repeating the graphs in the batch\n",
    "        x = x.unsqueeze(0).expand(self.num_runs, -1, -1).clone()   # Flattens features and creates num_runs copy of them \n",
    "        drop = torch.bernoulli(torch.ones([x.size(0), x.size(1)], device=x.device) * self.p).bool()   #  Returns a tensor of randomly dropped nodes based on p (p = probability of dropping) \n",
    "        x[drop] = torch.zeros([drop.sum().long().item(), x.size(-1)], device=x.device)  # Drop nodes from data  \n",
    "        del drop\n",
    "        \n",
    "        # Allow gradients to update base model \n",
    "        if self.training:\n",
    "            for layer in self.convs:\n",
    "                for p in layer.parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "            for layer in self.bns:\n",
    "                for p in layer.parameters():\n",
    "                    p.requires_grad = True\n",
    "        \n",
    "        # Run augmented subgraph through model \n",
    "        outs = [x]  # Used to store view of x after each layer \n",
    "        x = x.view(-1, x.size(-1))  # Swap dimensions of data features \n",
    "        run_edge_index = edge_index.repeat(1, self.num_runs) + torch.arange(self.num_runs, device=edge_index.device).repeat_interleave(edge_index.size(1)) * (edge_index.max() + 1) # Expand edge_index and augment values\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, run_edge_index)  # Run node features and edge indices through CONV layer \n",
    "            x = self.bns[i](x)  # Run resulting values through BatchNorm1d\n",
    "            x = F.relu(x)   # Run final values through RELU\n",
    "            outs.append(x.view(self.num_runs, -1, x.size(-1)))    # Rearrange dimensions and append to outs \n",
    "        del run_edge_index\n",
    "        \n",
    "        # Turn intermediate representation into contrastive representation\n",
    "        x = self.reps(x)\n",
    "        return x\n",
    "    \n",
    "    def prediction(self, data, dropout, num_runs):\n",
    "        self.dropout = dropout\n",
    "        self.num_runs = num_runs\n",
    "        \n",
    "        # Create intermediate representations \n",
    "        x = data.x \n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch \n",
    "        \n",
    "        # Do runs in parallel, by repeating the graphs in the batch\n",
    "        x = x.unsqueeze(0).expand(self.num_runs, -1, -1).clone()   # Flattens features and creates num_runs copy of them \n",
    "        drop = torch.bernoulli(torch.ones([x.size(0), x.size(1)], device=x.device) * self.p).bool()   #  Returns a tensor of randomly dropped nodes based on p (p = probability of dropping) \n",
    "        x[drop] = torch.zeros([drop.sum().long().item(), x.size(-1)], device=x.device)  # Drop nodes from data  \n",
    "        del drop\n",
    "        \n",
    "        # Stop gradients from updating base model \n",
    "        for layer in self.convs:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False\n",
    "                \n",
    "        for layer in self.bns:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Run augmented subgraph through model \n",
    "        outs = [x]  # Used to store view of x after each layer \n",
    "        x = x.view(-1, x.size(-1))  # Swap dimensions of data features \n",
    "        run_edge_index = edge_index.repeat(1, self.num_runs) + torch.arange(self.num_runs, device=edge_index.device).repeat_interleave(edge_index.size(1)) * (edge_index.max() + 1) # Expand edge_index and augment values\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, run_edge_index)  # Run node features and edge indices through CONV layer \n",
    "            x = self.bns[i](x)  # Run resulting values through BatchNorm1d\n",
    "            x = F.relu(x)   # Run final values through RELU\n",
    "            outs.append(x.view(self.num_runs, -1, x.size(-1)))    # Rearrange dimensions and append to outs \n",
    "        del run_edge_index\n",
    "        \n",
    "        # Aggregates results of runs by summing mean and applying random dropout (not dropping out nodes)\n",
    "        out = None\n",
    "        for i, x in enumerate(outs):\n",
    "            x = x.mean(dim=0)\n",
    "            x = global_add_pool(x, batch)\n",
    "            x = F.dropout(self.fcs[i](x), p=self.dropout, training=self.training)\n",
    "            if out is None:\n",
    "                out = x\n",
    "            else:\n",
    "                out += x\n",
    "\n",
    "        if self.use_aux_loss:\n",
    "            aux_out = torch.zeros(self.num_runs, out.size(0), out.size(1), device=out.device)\n",
    "            run_batch = batch.repeat(self.num_runs) + torch.arange(self.num_runs, device=edge_index.device).repeat_interleave(batch.size(0)) * (batch.max() + 1)\n",
    "            for i, x in enumerate(outs):\n",
    "                x = x.view(-1, x.size(-1))\n",
    "                x = global_add_pool(x, run_batch)\n",
    "                x = x.view(self.num_runs, -1, x.size(-1))\n",
    "                x = F.dropout(self.aux_fcs[i](x), p=self.dropout, training=self.training)\n",
    "                aux_out += x\n",
    "\n",
    "            # Returns probabilities of each class based on aggregated results \n",
    "            return F.log_softmax(out, dim=-1), F.log_softmax(aux_out, dim=-1)\n",
    "        else:\n",
    "            return F.log_softmax(out, dim=-1), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF6Gp8oIf2yR"
   },
   "source": [
    "## Training Modules\n",
    "\n",
    "NOTE: Currently, all training modules are for base DropGNN model\n",
    "\n",
    "Changes Made: \n",
    "- Added training function and validation function for contrastive learning \n",
    "- Added training function, validation function, and testing function for prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DropGIN Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GB8RAp5Lf2YJ"
   },
   "outputs": [],
   "source": [
    "# Default training function for original DropGIN\n",
    "def train(model, epoch, loader, optimizer):\n",
    "    # Set model to training \n",
    "    model.train()\n",
    "\n",
    "    # Run data through model and update model \n",
    "    loss_all = 0\n",
    "    n = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logs, aux_logs = model(data) \n",
    "        loss = F.nll_loss(logs, data.y) \n",
    "    \n",
    "        if model.use_aux_loss:\n",
    "            aux_loss = F.nll_loss(aux_logs.view(-1, aux_logs.size(-1)), data.y.unsqueeze(0).expand(aux_logs.size(0), -1).clone().view(-1))\n",
    "            loss = 0.75 * loss + 0.25 * aux_loss \n",
    "    \n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        n += len(data.y)\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "e36kqtIcpsN-"
   },
   "outputs": [],
   "source": [
    "# Default validation function for original DropGIN, uses nll loss \n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_all = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            logs, aux_logs = model(data)\n",
    "            loss_all += F.nll_loss(logs, data.y, reduction=\"sum\").item()\n",
    "    return loss_all / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wG80t0A3qRdg"
   },
   "outputs": [],
   "source": [
    "# Default test function for original DropGIN, uses accuracy \n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            logs, aux_logs = model(data) \n",
    "            pred = logs.max(1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Learning Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to train contrastive model \n",
    "def train_contrastive(model, loader, optimizer, p = 0.1):\n",
    "    # Set model to training\n",
    "    model.train()\n",
    "    \n",
    "    # Create self-supervised loss function\n",
    "    loss_func = losses.SelfSupervisedLoss(losses.TripletMarginLoss())\n",
    "    \n",
    "    # Run data through model and update model\n",
    "    loss_all = 0\n",
    "    n = 0 \n",
    "    for data in loader: \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data, mode = \"contrastive\", p = 0.0)\n",
    "        augmented = model(data, mode = \"contrastive\", p = p)\n",
    "        loss = loss_func(embeddings, augmented)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        n += data.num_graphs\n",
    "    return loss_all / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to validate contrastive model \n",
    "def valid_contrastive(model, loader, p = 0.1):\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_all = 0\n",
    "        for data in loader: \n",
    "            data = data.to(device)\n",
    "            embeddings = model(data, mode = \"contrastive\", p = 0.0)\n",
    "            augmented = model(data, mode = \"contrastive\", p = p)\n",
    "            loss = loss_func(embeddings, augmented)\n",
    "            \n",
    "            loss_all += data.num_graphs * loss.item()\n",
    "            n += data.num_graphs\n",
    "            \n",
    "    return loss_all / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to train prediction model AFTER contrastive learning \n",
    "def train_prediction(model, loader, optimizer, dropout = 0.5):\n",
    "    # Set model to training\n",
    "    model.train()\n",
    "    \n",
    "    # Run data through model and update model \n",
    "    loss_all = 0\n",
    "    n = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logs, aux_logs = model(data, mode = \"prediction\", dropout = dropout)\n",
    "        loss = F.nll_loss(logs, data.y)\n",
    "        \n",
    "        if model.use_aux_loss:\n",
    "            aux_loss = F.nll_loss(aux_logs.view(-1, aux_logs.size(-1)), data.y.unsqueeze(0).expand(aux_logs.size(0), -1).clone().view(-1))\n",
    "            loss = 0.75 * loss + 0.25 * aux_loss \n",
    "    \n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        n += len(data.y)\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to validate prediction model AFTER contrastive learning, returns loss \n",
    "def valid_prediction(model, loader, dropout = 0.5):\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    # Run data through model\n",
    "    with torch.no_grad():\n",
    "        loss_all = 0\n",
    "        n = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            logs, aux_logs = model(data, mode = \"prediction\", dropout = dropout)\n",
    "            loss = F.nll_loss(logs, data.y)\n",
    "\n",
    "            if model.use_aux_loss:\n",
    "                aux_loss = F.nll_loss(aux_logs.view(-1, aux_logs.size(-1)), data.y.unsqueeze(0).expand(aux_logs.size(0), -1).clone().view(-1))\n",
    "                loss = 0.75 * loss + 0.25 * aux_loss \n",
    "                \n",
    "            loss_all += data.num_graphs * loss.item()\n",
    "            n += len(data.y)\n",
    "\n",
    "    return loss_all / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to test prediction model AFTER contrastive learning, returns accuracy\n",
    "def test_prediction(model, loader, dropout = 0.5):\n",
    "    # Set model to eval\n",
    "    model.eval() \n",
    "    \n",
    "    # Run data through model \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for data in loader: \n",
    "            data = data.to(device)\n",
    "            logs, aux_logs = model(data, mode = \"prediction\", dropout = dropout)\n",
    "            pred = logs.max(1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyriXAImrdTd"
   },
   "source": [
    "## Split Dataset into K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3wui_6Yerfn-"
   },
   "outputs": [],
   "source": [
    "def separate_data(dataset_len, seed=0):\n",
    "    folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    idx_list = []\n",
    "    for idx in folds.split(np.zeros(dataset_len), np.zeros(dataset_len)):\n",
    "        idx_list.append(idx)\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK_8wBdMgBjj"
   },
   "source": [
    "## Run DropGIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQjeCJN-c8og",
    "outputId": "fe7dd714-7d4d-4de8-a3ad-42e2eacae683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set batch size\n",
    "BATCH = 32    # Default batch size in DropGNN\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7qE6ky4lgAFF"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = DropGIN(64, 0.5).to(device)\n",
    "\n",
    "# Split dataset\n",
    "n = len(dataset)\n",
    "splits = separate_data(n, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diafNwnnsw1d",
    "outputId": "4a95e6a7-31bd-46d4-9020-05c85ab17924"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "acc = []\n",
    "for i, (train_idx, valid_idx) in enumerate(splits[2:3]): # TODO: Change back to all splits\n",
    "    model.reset_parameters()    # Resets upon every new fold \n",
    "    lr = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5) # Used to learn learning rate \n",
    "  \n",
    "    valid_dataset = dataset[valid_idx.tolist()]\n",
    "    train_dataset = dataset[train_idx.tolist()]\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=BATCH)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, sampler=torch.utils.data.RandomSampler(train_dataset, replacement=True, num_samples=int(len(train_dataset)*50/(len(train_dataset)/BATCH))), batch_size=BATCH, drop_last=False, collate_fn=Collater(follow_batch=[],exclude_keys=[]))\n",
    "\n",
    "    # Train model for multiple epochs\n",
    "    valid_acc = 0 \n",
    "    acc_temp = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        if epoch % 25 == 0:\n",
    "            start = time.time()\n",
    "\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        train_loss = train(model, epoch, train_loader, optimizer)\n",
    "        scheduler.step()\n",
    "        valid_acc = test(model, valid_loader)\n",
    "        acc_temp.append(valid_acc)\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            print('Epoch: {:03d}, LR: {:7f}, Train Loss: {:.7f}, '\n",
    "                'Val Loss: {:.7f}, Test Acc: {:.7f}, Time: {:7f}'.format(\n",
    "                    epoch, lr, train_loss, 0, valid_acc, time.time() - start), flush=True)\n",
    "\n",
    "    acc.append(torch.tensor(acc_temp))\n",
    "\n",
    "acc = torch.stack(acc, dim=0)\n",
    "acc_mean = acc.mean(dim=0)\n",
    "best_epoch = acc_mean.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Uu-W5AzzMoH",
    "outputId": "2dff7bd7-286e-41d3-ac71-2c32ed8f4232"
   },
   "outputs": [],
   "source": [
    "# Note: std won't work if only using one k-fold \n",
    "\n",
    "print('---------------- Final Epoch Result ----------------')\n",
    "print('Mean: {:7f}, Std: {:7f}'.format(acc[:,-1].mean(), acc[:,-1].std()))\n",
    "print(f'---------------- Best Epoch: {best_epoch} ----------------')\n",
    "print('Mean: {:7f}, Std: {:7f}'.format(acc[:,best_epoch].mean(), acc[:,best_epoch].std()), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DropGNN + Contrastive Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set batch size\n",
    "BATCH = 32    # Default batch size in DropGNN\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = DropGNN_Contrastive(num_features=dataset.num_features, num_reps=8, num_classes=dataset.num_classes, hidden_units=64).to(device)\n",
    "\n",
    "# Split dataset\n",
    "n = len(dataset)\n",
    "splits = separate_data(n, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2436.96 GiB (GPU 0; 10.76 GiB total capacity; 541.39 MiB already allocated; 9.01 GiB free; 578.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m lr \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_contrastive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m valid_contrastive(model, test_loader, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 17\u001b[0m, in \u001b[0;36mtrain_contrastive\u001b[0;34m(model, loader, optimizer, p)\u001b[0m\n\u001b[1;32m     15\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model(data, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrastive\u001b[39m\u001b[38;5;124m\"\u001b[39m, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     16\u001b[0m augmented \u001b[38;5;241m=\u001b[39m model(data, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrastive\u001b[39m\u001b[38;5;124m\"\u001b[39m, p \u001b[38;5;241m=\u001b[39m p)\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \n",
      "File \u001b[0;32m/opt/conda/envs/DropGNN/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_metric_learning/losses/self_supervised_loss.py:57\u001b[0m, in \u001b[0;36mSelfSupervisedLoss.forward\u001b[0;34m(self, embeddings, ref_emb)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03membeddings: representations of the original set of inputs\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mref_emb:    representations of an augmentation of the inputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m            i.e. ref_emb2, ref_emb3, ...\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/DropGNN/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py:34\u001b[0m, in \u001b[0;36mBaseMetricLossFunction.forward\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mto_device(labels, embeddings)\n\u001b[1;32m     33\u001b[0m ref_emb, ref_labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mset_ref_emb(embeddings, labels, ref_emb, ref_labels)\n\u001b[0;32m---> 34\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embedding_regularization_to_loss_dict(loss_dict, embeddings)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(loss_dict, embeddings, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_metric_learning/losses/triplet_margin_loss.py:36\u001b[0m, in \u001b[0;36mTripletMarginLoss.compute_loss\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, embeddings, labels, indices_tuple, ref_emb, ref_labels):\n\u001b[1;32m     35\u001b[0m     c_f\u001b[38;5;241m.\u001b[39mlabels_or_indices_tuple_required(labels, indices_tuple)\n\u001b[0;32m---> 36\u001b[0m     indices_tuple \u001b[38;5;241m=\u001b[39m \u001b[43mlmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_triplets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_per_anchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplets_per_anchor\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     anchor_idx, positive_idx, negative_idx \u001b[38;5;241m=\u001b[39m indices_tuple\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(anchor_idx) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py:186\u001b[0m, in \u001b[0;36mconvert_to_triplets\u001b[0;34m(indices_tuple, labels, ref_labels, t_per_anchor)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices_tuple \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t_per_anchor \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_all_triplets_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_random_triplet_indices(\n\u001b[1;32m    189\u001b[0m             labels, ref_labels, t_per_anchor\u001b[38;5;241m=\u001b[39mt_per_anchor\n\u001b[1;32m    190\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py:89\u001b[0m, in \u001b[0;36mget_all_triplets_indices\u001b[0;34m(labels, ref_labels)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_triplets_indices\u001b[39m(labels, ref_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     88\u001b[0m     matches, diffs \u001b[38;5;241m=\u001b[39m get_matches_and_diffs(labels, ref_labels)\n\u001b[0;32m---> 89\u001b[0m     triplets \u001b[38;5;241m=\u001b[39m \u001b[43mmatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiffs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mwhere(triplets)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2436.96 GiB (GPU 0; 10.76 GiB total capacity; 541.39 MiB already allocated; 9.01 GiB free; 578.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Run contrastive learning \n",
    "# Train model\n",
    "loss = []\n",
    "for i, (train_idx, test_idx) in enumerate(splits[:1]): # TODO: Change back to all splits\n",
    "    model.reset_parameters()    # Resets upon every new fold \n",
    "    lr = 0.01\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5) # Used to learn learning rate \n",
    "  \n",
    "    train_dataset = dataset[train_idx.tolist()]\n",
    "    test_dataset = dataset[test_idx.tolist()]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, sampler=torch.utils.data.RandomSampler(train_dataset, replacement=True, num_samples=int(len(train_dataset)*50/(len(train_dataset)/BATCH))), batch_size=BATCH, drop_last=False, collate_fn=Collater(follow_batch=[],exclude_keys=[]))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH)\n",
    "\n",
    "    # Train model for multiple epochs\n",
    "    test_loss = 0 \n",
    "    loss_temp = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        if epoch % 25 == 0:\n",
    "            start = time.time()\n",
    "\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        train_loss = train_contrastive(model, train_loader, optimizer, p=0.1)\n",
    "        scheduler.step()\n",
    "        test_loss = valid_contrastive(model, test_loader, p=0.1)\n",
    "        loss_temp.append(test_loss)\n",
    "\n",
    "        if epoch % 25 == 0:\n",
    "            print('Epoch: {:03d}, LR: {:7f}, Train Loss: {:.7f}, '\n",
    "                'Val Loss: {:.7f}, Time: {:7f}'.format(\n",
    "                    epoch, lr, train_loss, test_loss, time.time() - start), flush=True)\n",
    "\n",
    "    loss.append(torch.tensor(loss_temp))\n",
    "\n",
    "loss = torch.stack(loss, dim=0)\n",
    "loss_mean = loss.mean(dim=0)\n",
    "best_epoch = loss_mean.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMDB-BINARY(996)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IMDB-BINARY(10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x7f1f50171c70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10] + dataset[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 120], x=[15, 69], y=[1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.ConcatDataset([dataset[:50], dataset[-50:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
